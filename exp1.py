# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1J2fXRuRwaLfdBwkvwDqT9OWK5U8i7v1D
"""

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import mnist
from sklearn.preprocessing import OneHotEncoder
(x_train,y_train),(_,_)=mnist.load_data()
x_train=x_train.reshape(-1,784)/255.0
encoder=OneHotEncoder(sparse_output=False)
y_train = encoder.fit_transform(y_train.reshape(-1, 1))
input_size,hidden_size,output_size=784,64,10
w1=np.random.randn(input_size,hidden_size)*0.01
w2=np.random.randn(hidden_size,output_size)*0.01
b1=np.zeros((1,hidden_size))
b2=np.zeros((1,output_size))
sigmoid=lambda x:1/(1+np.exp(-x))
sigmoid_deriv=lambda x:x*(1-x)
loss_fn=lambda y,y_hat:-np.mean(y*np.log(y_hat+1e-8))
epochs, lr = 10, 0.1
losses = []
for epoch in range(epochs):
    total_loss = 0
    for i in range(x_train.shape[0]):
        x = x_train[i:i+1]
        y = y_train[i:i+1]
        z1 = x @ w1 + b1
        a1 = sigmoid(z1)
        z2 = a1 @ w2 + b2
        a2 = sigmoid(z2)
        loss = loss_fn(y, a2)
        total_loss += loss
        dz2 = a2 - y
        dw2 = a1.T @ dz2
        db2 = dz2
        dz1 = (dz2 @ w2.T) * sigmoid_deriv(a1)
        dw1 = x.T @ dz1
        db1 = dz1
        w2 -= lr * dw2
        b2 -= lr * db2
        w1 -= lr * dw1
        b1 -= lr * db1
    losses.append(total_loss / x_train.shape[0])
    print(f"Epoch {epoch+1}, Loss: {losses[-1]:.4f}")
plt.plot(losses)
plt.title("training loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.grid(True)
plt.show()
def predict(img):
    img = img.reshape(1, 784) / 255.0
    a1 = sigmoid(img @ w1 + b1)
    a2 = sigmoid(a1 @ w2 + b2)
    return np.argmax(a2)
idx = 100
plt.imshow(x_train[idx].reshape(28, 28), cmap='gray')
plt.title(f"Prediction: {predict(x_train[idx])}")
plt.axis('off')
plt.show()

pip install tensorflow